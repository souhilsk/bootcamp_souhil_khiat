{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3848df1c",
   "metadata": {},
   "source": [
    "# Setup: Generate Sample Dataset\n",
    "\n",
    "This cell creates the required folder structure (`data/raw/` and `data/processed/`) relative to the notebook, and generates the sample CSV dataset with missing values. \n",
    "This ensures the dataset is ready for cleaning functions and saves it to `data/raw/outliers_homework.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c50b376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists at ../data/raw/outliers_homework.csv. Skipping CSV creation to avoid overwrite.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define folder paths relative to this notebook\n",
    "raw_dir = '../data/raw'\n",
    "processed_dir = '../data/processed'\n",
    "\n",
    "# Create folders if they don't exist\n",
    "os.makedirs(raw_dir, exist_ok=True)\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "# Generate business day dates\n",
    "dates = pd.date_range(start=\"2022-01-03\", end=\"2022-06-10\", freq=\"B\")\n",
    "\n",
    "# Fixed random seed for reproducibility\n",
    "np.random.seed(17)\n",
    "\n",
    "# Column 1: daily_return ~ N(0, 0.01)\n",
    "returns = np.random.normal(0, 0.01, size=len(dates))\n",
    "mask_pre_may = dates < \"2022-05-01\"\n",
    "returns[mask_pre_may] -= 0.0015  \n",
    "\n",
    "# Inject \"shock\" values\n",
    "shock_values = {\n",
    "    \"2022-05-02\": 0.1748425237194541,\n",
    "    \"2022-05-03\": -0.16825801732486943,\n",
    "    \"2022-05-06\": -0.19667220757153227,\n",
    "    \"2022-05-09\": 0.21240223590614747,\n",
    "    \"2022-05-12\": -0.178729287231294\n",
    "}\n",
    "for d, v in shock_values.items():\n",
    "    idx = np.where(dates == pd.to_datetime(d))[0][0]\n",
    "    returns[idx] = v\n",
    "\n",
    "# Column 2: daily_return_2, correlated with daily_return + small noise\n",
    "daily_return_2 = returns * 0.6 + np.random.normal(0, 0.005, size=len(dates))\n",
    "\n",
    "# Create DataFrame with two numeric columns\n",
    "df = pd.DataFrame({\n",
    "    \"date\": dates,\n",
    "    \"daily_return\": returns,\n",
    "    \"daily_return_2\": daily_return_2\n",
    "})\n",
    "\n",
    "# Save to CSV in raw data folder\n",
    "csv_path = os.path.join(raw_dir, 'outliers_homework.csv')\n",
    "if not os.path.exists(csv_path):\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f'Synthetic dataset with two columns created and saved to {csv_path}')\n",
    "else:\n",
    "    print(f'File already exists at {csv_path}. Skipping CSV creation to avoid overwrite.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c858afa4",
   "metadata": {},
   "source": [
    "# Stage 7 Homework â€” Outliers + Risk Assumptions\n",
    "In this assignment you will implement outlier detection/handling and run a simple sensitivity analysis.\n",
    "\n",
    "**Chain:** In the lecture, we learned detection (IQR, Z-score), options for handling (remove/winsorize), and sensitivity testing. Now, you will adapt those methods to a provided dataset and document the risks and assumptions behind your choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9bf9a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "np.random.seed(17)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6542c1",
   "metadata": {},
   "source": [
    "## Load Data (provided or synthetic fallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad6c0c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.331519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.050251</td>\n",
       "      <td>-1.115001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100503</td>\n",
       "      <td>1.969787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.150754</td>\n",
       "      <td>2.706032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.201005</td>\n",
       "      <td>2.686840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y\n",
       "0  0.000000  1.331519\n",
       "1  0.050251 -1.115001\n",
       "2  0.100503  1.969787\n",
       "3  0.150754  2.706032\n",
       "4  0.201005  2.686840"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path('data/raw/outliers_homework.csv')\n",
    "if data_path.exists():\n",
    "    df = pd.read_csv(data_path)\n",
    "else:\n",
    "    # Synthetic fallback: linear trend with noise and a few extremes\n",
    "    x = np.linspace(0, 10, 200)\n",
    "    y = 2.2 * x + 1 + np.random.normal(0, 1.2, size=x.size)\n",
    "    y[10] += 15; y[120] -= 13; y[160] += 18\n",
    "    df = pd.DataFrame({'x': x, 'y': y})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c410a60",
   "metadata": {},
   "source": [
    "## TODO: Implement Outlier Functions (required)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05816864",
   "metadata": {},
   "source": [
    "### `detect_outliers_iqr(series)`\n",
    "Detect outliers in a numeric pandas Series using Tukey's IQR rule.\n",
    "\n",
    "**Rule:** A point is an outlier if it lies below `Q1 - 1.5 * IQR` or above `Q3 + 1.5 * IQR`,  \n",
    "where `IQR = Q3 - Q1` and `Qk` are the 25th and 75th percentiles.\n",
    "\n",
    "**Parameters**\n",
    "- `series` *(pd.Series)*: numeric series; NaNs are ignored.\n",
    "\n",
    "**Returns**\n",
    "- `pd.Series[bool]`: Boolean mask aligned to the input index; `True` where the value is an outlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a4882cf",
   "metadata": {
    "tags": [
     "grade_required"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def detect_outliers_iqr(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Detect outliers via Tukey's IQR rule.\n",
    "    \n",
    "    A value x is flagged as an outlier if x < Q1 - 1.5*IQR or x > Q3 + 1.5*IQR,\n",
    "    where IQR = Q3 - Q1 computed ignoring NaNs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    series : pd.Series\n",
    "        Numeric Series. NaNs are ignored in quantile computation.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series of bool\n",
    "        Boolean mask with the same index as `series` where True marks outliers.\n",
    "    \"\"\"\n",
    "    if not isinstance(series, pd.Series):\n",
    "        series = pd.Series(series)\n",
    "    s = pd.to_numeric(series, errors=\"coerce\")\n",
    "    q1 = s.quantile(0.25)\n",
    "    q3 = s.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    # Guard against zero IQR (e.g., constant series) to avoid false positives\n",
    "    if pd.isna(iqr) or iqr == 0:\n",
    "        return pd.Series(False, index=series.index)\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    out = (s < lower) | (s > upper)\n",
    "    # Keep NaNs as False\n",
    "    out = out.fillna(False)\n",
    "    out.name = getattr(series, \"name\", None)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e28480",
   "metadata": {},
   "source": [
    "*(Stretch)* Implement winsorizing (optional)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a3b54c",
   "metadata": {},
   "source": [
    "### `winsorize_series(series, lower=0.05, upper=0.95)` *(stretch)*\n",
    "Winsorize a numeric series by **clipping** extreme values to specified quantiles.\n",
    "\n",
    "**Parameters**\n",
    "- `series` *(pd.Series)*: numeric series; NaNs preserved.\n",
    "- `lower` *(float, default 0.05)*: lower quantile in \\[0, 0.5); set to 0 for no lower clipping.\n",
    "- `upper` *(float, default 0.95)*: upper quantile in (0.5, 1]; set to 1 for no upper clipping.\n",
    "\n",
    "**Returns**\n",
    "- `pd.Series`: Series with values clipped to `[Q_lower, Q_upper]`, index preserved.\n",
    "\n",
    "**Notes**\n",
    "- Winsorization reduces the influence of extreme values without removing observations.\n",
    "- If `lower >= upper`, no clipping is applied.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bea1067",
   "metadata": {
    "tags": [
     "stretch"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def winsorize_series(series: pd.Series, lower: float = 0.05, upper: float = 0.95) -> pd.Series:\n",
    "    \"\"\"Winsorize a numeric Series by clipping values to the given quantiles.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    series : pd.Series\n",
    "        Numeric Series to winsorize. Non-numeric values are coerced to NaN.\n",
    "    lower : float, default 0.05\n",
    "        Lower quantile (0 <= lower < 0.5). Set to 0 to disable lower clipping.\n",
    "    upper : float, default 0.95\n",
    "        Upper quantile (0.5 < upper <= 1). Set to 1 to disable upper clipping.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        Winsorized series with same index as input; NaNs preserved.\n",
    "    \"\"\"\n",
    "    if not isinstance(series, pd.Series):\n",
    "        series = pd.Series(series)\n",
    "    s = pd.to_numeric(series, errors=\"coerce\")\n",
    "    # Validate bounds\n",
    "    try:\n",
    "        lower_f = float(lower)\n",
    "        upper_f = float(upper)\n",
    "    except Exception:\n",
    "        lower_f, upper_f = 0.05, 0.95\n",
    "    if not (0 <= lower_f <= 1 and 0 <= upper_f <= 1):\n",
    "        lower_f, upper_f = 0.05, 0.95\n",
    "    if lower_f >= upper_f:\n",
    "        # Degenerate case: return original casted series\n",
    "        return s\n",
    "    \n",
    "    q_low = s.quantile(lower_f)\n",
    "    q_high = s.quantile(upper_f)\n",
    "    # Clip; preserve dtype if possible\n",
    "    w = s.clip(lower=q_low, upper=q_high)\n",
    "    w.name = getattr(series, \"name\", None)\n",
    "    # If original looked like ints and no NaNs, try to cast back to int\n",
    "    if pd.api.types.is_integer_dtype(series.dtype) and not w.isna().any():\n",
    "        try:\n",
    "            w = w.astype(series.dtype)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22043b7",
   "metadata": {},
   "source": [
    "## Apply Detection and Create Flags (choose a numeric column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd4f6f1d",
   "metadata": {
    "tags": [
     "grade_required"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'detect_outliers_zscore' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m target_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01melse\u001b[39;00m df\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutlier_iqr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m detect_outliers_iqr(df[target_col])\n\u001b[0;32m----> 3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutlier_z\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_outliers_zscore\u001b[49m(df[target_col], threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3.0\u001b[39m)\n\u001b[1;32m      4\u001b[0m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutlier_iqr\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutlier_z\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# fraction flagged\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'detect_outliers_zscore' is not defined"
     ]
    }
   ],
   "source": [
    "target_col = 'y' if 'y' in df.columns else df.select_dtypes(include=['number']).columns[0]\n",
    "df['outlier_iqr'] = detect_outliers_iqr(df[target_col])\n",
    "df['outlier_z'] = detect_outliers_zscore(df[target_col], threshold=3.0)\n",
    "df[['outlier_iqr', 'outlier_z']].mean()  # fraction flagged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a8e975",
   "metadata": {},
   "source": [
    "### Visual Checks (boxplot / histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e532d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.boxplot(df[target_col])\n",
    "plt.title(f'Boxplot: {target_col}')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(df[target_col], bins=30)\n",
    "plt.title(f'Histogram: {target_col}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a84793f",
   "metadata": {},
   "source": [
    "## Sensitivity Analysis\n",
    "Pick one: summary stats or simple linear regression comparing **all vs. filtered** (and optional winsorized)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1664d7e9",
   "metadata": {
    "tags": [
     "grade_required"
    ]
   },
   "outputs": [],
   "source": [
    "# Option A: Summary stats\n",
    "summ_all = df[target_col].describe()[['mean', '50%', 'std']].rename({'50%': 'median'})\n",
    "summ_filtered = df.loc[~df['outlier_iqr'], target_col].describe()[['mean', '50%', 'std']].rename({'50%': 'median'})\n",
    "summ_w = None\n",
    "if 'winsorize_series' in globals():\n",
    "    w = winsorize_series(df[target_col])\n",
    "    summ_w = w.describe()[['mean', '50%', 'std']].rename({'50%': 'median'})\n",
    "\n",
    "comp = pd.concat(\n",
    "    {\n",
    "        'all': summ_all,\n",
    "        'filtered_iqr': summ_filtered,\n",
    "        **({'winsorized': summ_w} if summ_w is not None else {})\n",
    "    }, axis=1\n",
    ")\n",
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f3edde",
   "metadata": {
    "tags": [
     "grade_required"
    ]
   },
   "outputs": [],
   "source": [
    "# Option B: Simple regression (if x present)\n",
    "if 'x' in df.columns:\n",
    "    X_all = df[['x']].to_numpy(); y_all = df[target_col].to_numpy()\n",
    "    X_filtered = df.loc[~df['outlier_iqr'], ['x']].to_numpy(); y_filtered = df.loc[~df['outlier_iqr'], target_col].to_numpy()\n",
    "\n",
    "    model_all = LinearRegression().fit(X_all, y_all)\n",
    "    model_flt = LinearRegression().fit(X_filtered, y_filtered)\n",
    "\n",
    "    mae_all = mean_absolute_error(y_all, model_all.predict(X_all))\n",
    "    mae_flt = mean_absolute_error(y_filtered, model_flt.predict(X_filtered))\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        'slope': [model_all.coef_[0], model_flt.coef_[0]],\n",
    "        'intercept': [model_all.intercept_, model_flt.intercept_],\n",
    "        'r2': [model_all.score(X_all, y_all), model_flt.score(X_filtered, y_filtered)],\n",
    "        'mae': [mae_all, mae_flt]\n",
    "    }, index=['all', 'filtered_iqr'])\n",
    "    results\n",
    "else:\n",
    "    results = None\n",
    "    print(\"No 'x' column; skip regression or engineer features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e59ad7a",
   "metadata": {},
   "source": [
    "### Reflection (â‰¤ 1 page)\n",
    "- Methods and thresholds used (and why)\n",
    "- Assumptions behind choices\n",
    "- Observed impact on results\n",
    "- Risks if assumptions are wrong (e.g., discarding true events)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63bfd09",
   "metadata": {},
   "source": [
    "*Write your reflection here...*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d519162",
   "metadata": {},
   "source": [
    "### `detect_outliers_zscore(series, threshold=3.0)`\n",
    "Detect outliers using **standard score (zâ€‘score)**.\n",
    "\n",
    "**Rule:** A point is an outlier if `|z| > threshold`, with `z = (x âˆ’ Î¼)/Ïƒ`  \n",
    "computed from the sample mean `Î¼` and sample standard deviation `Ïƒ` (ddof=0).\n",
    "\n",
    "**Parameters**\n",
    "- `series` *(pd.Series)*: numeric series; NaNs are ignored when computing Î¼ and Ïƒ.\n",
    "- `threshold` *(float, default 3.0)*: zâ€‘score cutoff (common choices: 3.0, 2.5).\n",
    "\n",
    "**Returns**\n",
    "- `pd.Series[bool]`: Boolean mask aligned to the input index; `True` where the value is an outlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da30b0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_zscore(series: pd.Series, threshold: float = 3.0) -> pd.Series:\n",
    "    \"\"\"Detect outliers via z-score with a configurable threshold.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    series : pd.Series\n",
    "        Numeric Series. NaNs are ignored when fitting mean/std.\n",
    "    threshold : float, default 3.0\n",
    "        Absolute z-score above which a point is flagged as an outlier.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series of bool\n",
    "        Boolean mask with the same index as `series` where True marks outliers.\n",
    "    \"\"\"\n",
    "    if not isinstance(series, pd.Series):\n",
    "        series = pd.Series(series)\n",
    "    s = pd.to_numeric(series, errors=\"coerce\")\n",
    "    mu = s.mean(skipna=True)\n",
    "    sigma = s.std(skipna=True, ddof=0)\n",
    "    if pd.isna(sigma) or sigma == 0:\n",
    "        return pd.Series(False, index=series.index)\n",
    "    z = (s - mu) / sigma\n",
    "    out = z.abs() > threshold\n",
    "    out = out.fillna(False)\n",
    "    out.name = getattr(series, \"name\", None)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591418ae",
   "metadata": {},
   "source": [
    "#### Quick sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c559108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick sanity checks\n",
    "s = pd.Series([1, 2, 2, 2, 3, 100, -50, None, 2, 2, 3], name=\"demo\")\n",
    "\n",
    "print(\"IQR outliers:\")\n",
    "print(detect_outliers_iqr(s))\n",
    "\n",
    "print(\"\\nZ-score outliers (threshold=2.5):\")\n",
    "print(detect_outliers_zscore(s, threshold=2.5))\n",
    "\n",
    "print(\"\\nWinsorized (5th/95th percentiles):\")\n",
    "print(winsorize_series(s, 0.05, 0.95))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbeee4e",
   "metadata": {},
   "source": [
    "\n",
    "# Stage 7 â€” Outliers + Risk Assumptions (Completed)\n",
    "\n",
    "This notebook implements reusable outlier utilities (IQR, Z-score, Winsorization), applies them to data, and runs a small sensitivity analysis (summary stats + simple regression) **with vs. without outliers** and **winsorized**. Plots and a short reflection are included to match the assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65eb03f7",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f33ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "csv_path = \"data/raw/outliers_homework.csv\"\n",
    "if os.path.exists(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "else:\n",
    "    # Synthetic fallback: linear relation with noise and a few injected outliers\n",
    "    n = 300\n",
    "    x = np.random.normal(50, 10, size=n)\n",
    "    y = 2.5 * x + np.random.normal(0, 12, size=n)\n",
    "    # Inject a few outliers\n",
    "    x[:5] = x[:5] + np.array([80, -70, 100, -90, 60])\n",
    "    y[:5] = y[:5] + np.array([300, -280, 350, -330, 250])\n",
    "    df = pd.DataFrame({\"feature_x\": x, \"target_y\": y})\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe1e372",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Outlier flags\n",
    "We will use `feature_x` as the explanatory variable and `target_y` as the response for modeling. Below we build boolean masks for outliers using both IQR and Z-score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc4a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pick columns (adapt here if your CSV uses different names)\n",
    "num_col = \"feature_x\" if \"feature_x\" in df.columns else df.select_dtypes(\"number\").columns[0]\n",
    "y_col = \"target_y\" if \"target_y\" in df.columns else (df.select_dtypes(\"number\").columns[1] if df.select_dtypes(\"number\").shape[1] > 1 else None)\n",
    "\n",
    "iqr_mask = detect_outliers_iqr(df[num_col])\n",
    "z_mask = detect_outliers_zscore(df[num_col], threshold=3.0)\n",
    "df[\"outlier_iqr\"] = iqr_mask\n",
    "df[\"outlier_zscore\"] = z_mask\n",
    "\n",
    "df[[num_col, \"outlier_iqr\", \"outlier_zscore\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21e00da",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Sensitivity â€” Summary stats (mean/median/std)\n",
    "We compare **all data**, **filtered by IQR (no outliers)**, and **winsorized** for the chosen column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb87d4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Winsorize chosen series\n",
    "w_series = winsorize_series(df[num_col], lower=0.05, upper=0.95)\n",
    "\n",
    "def stats(s):\n",
    "    return pd.Series({\n",
    "        \"mean\": s.mean(),\n",
    "        \"median\": s.median(),\n",
    "        \"std\": s.std(ddof=1),\n",
    "        \"min\": s.min(),\n",
    "        \"max\": s.max(),\n",
    "        \"count\": s.shape[0]\n",
    "    })\n",
    "\n",
    "stats_all = stats(df[num_col].dropna())\n",
    "stats_filtered = stats(df.loc[~df[\"outlier_iqr\"], num_col].dropna())\n",
    "stats_wins = stats(w_series.dropna())\n",
    "\n",
    "summary_table = pd.concat([stats_all, stats_filtered, stats_wins], axis=1)\n",
    "summary_table.columns = [\"all\", \"no_outliers_iqr\", \"winsorized\"]\n",
    "summary_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b206ed13",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Boxplots â€” before vs. winsorized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7968812",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.boxplot([df[num_col].dropna().values, w_series.dropna().values], labels=[\"All\", \"Winsorized\"])\n",
    "plt.title(f\"Boxplots for {num_col} (All vs Winsorized)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2510e0bc",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Simple Linear Regression â€” with vs. without outliers (plus winsorized)\n",
    "We fit `target_y ~ feature_x` (or the first two numeric columns) and compare coefficients and fit metrics across three treatments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c5332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "# Choose y if not set; if no second numeric column exists, synthesize target\n",
    "if y_col is None or y_col not in df.columns:\n",
    "    # Synthesize a target as a noisy linear function of num_col\n",
    "    y_col = \"target_synth\"\n",
    "    df[y_col] = 2.5 * df[num_col] + np.random.normal(0, 12, size=len(df))\n",
    "\n",
    "def fit_and_report(X_series, y_series, label):\n",
    "    mask = (~X_series.isna()) & (~y_series.isna())\n",
    "    X = X_series[mask].values.reshape(-1, 1)\n",
    "    y = y_series[mask].values\n",
    "    model = LinearRegression().fit(X, y)\n",
    "    y_hat = model.predict(X)\n",
    "    return pd.Series({\n",
    "        \"label\": label,\n",
    "        \"coef\": float(model.coef_[0]),\n",
    "        \"intercept\": float(model.intercept_),\n",
    "        \"R2\": float(r2_score(y, y_hat)),\n",
    "        \"MAE\": float(mean_absolute_error(y, y_hat)),\n",
    "        \"n\": int(mask.sum())\n",
    "    })\n",
    "\n",
    "# Variants\n",
    "all_fit = fit_and_report(df[num_col], df[y_col], \"all\")\n",
    "no_outliers_fit = fit_and_report(df.loc[~df[\"outlier_iqr\"], num_col], df.loc[~df[\"outlier_iqr\"], y_col], \"no_outliers_iqr\")\n",
    "wins_fit = fit_and_report(w_series, df[y_col], \"winsorized\")\n",
    "\n",
    "reg_table = pd.concat([all_fit, no_outliers_fit, wins_fit], axis=1).T.set_index(\"label\")\n",
    "reg_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d171ed",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Residuals â€” visual check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e85196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def residuals_series(X_series, y_series):\n",
    "    mask = (~X_series.isna()) & (~y_series.isna())\n",
    "    X = X_series[mask].values.reshape(-1, 1)\n",
    "    y = y_series[mask].values\n",
    "    m = LinearRegression().fit(X, y)\n",
    "    return pd.Series(y - m.predict(X), index=X_series[mask].index)\n",
    "\n",
    "res_all = residuals_series(df[num_col], df[y_col])\n",
    "res_no = residuals_series(df.loc[~df[\"outlier_iqr\"], num_col], df.loc[~df[\"outlier_iqr\"], y_col])\n",
    "res_win = residuals_series(w_series, df[y_col])\n",
    "\n",
    "plt.figure()\n",
    "plt.boxplot([res_all.values, res_no.values, res_win.values], labels=[\"All\", \"No outliers (IQR)\", \"Winsorized\"])\n",
    "plt.title(\"Residuals distribution across treatments\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca58aa52",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Reflection (â‰¤ 1 page)\n",
    "\n",
    "**Method choice & thresholds.**  \n",
    "- IQR with 1.5Ã—IQR was used to flag and **remove** outliers for the filtered variant.  \n",
    "- Z-score at 3.0 is implemented but not used in the main comparison; it tends to be sensitive to outliers if the distribution is heavyâ€‘tailed.  \n",
    "- Winsorization at [5%, 95%] was used to **limit influence** without dropping rows.\n",
    "\n",
    "**Assumptions.**  \n",
    "- The core numeric feature is roughly unimodal with a majority of inliers.  \n",
    "- The linear model is an adequate firstâ€‘order summary for sensitivity purposes.  \n",
    "- Winsorized quantiles are stable (enough data).\n",
    "\n",
    "**Observed impacts.**  \n",
    "- Compare the tables above: removing outliers stabilizes the mean and reduces std; coefficients and MAE typically improve, and RÂ² often increases. Winsorization provides a middle ground. \n",
    "\n",
    "**Risks if wrong.**  \n",
    "- If extreme values are genuine and predictive, removing them biases conclusions.  \n",
    "- If the distribution is strongly skewed/heavyâ€‘tailed, z-score may underâ€‘ or overâ€‘flag.  \n",
    "- Winsorization masks extremes, which could be critical for riskâ€‘sensitive applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e659d0df-8d95-4434-bb80-b971715b1581",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
